{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-access-data#python-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datastore for sample images (from public account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.datastore import Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchscore_blob = Datastore.register_azure_blob_container(ws, \n",
    "                      datastore_name=\"images_datastore\", \n",
    "                      container_name=\"sampledata\", \n",
    "                      account_name=\"pipelinedata\", \n",
    "                      overwrite=True)\n",
    "def_data_store = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "from azureml.pipeline.core import PipelineData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = Dataset.File.from_files((batchscore_blob, \"batchscoring/images/\"))\n",
    "label_ds = Dataset.File.from_files((batchscore_blob, \"batchscoring/labels/\"))\n",
    "output_dir = PipelineData(name=\"scores\", \n",
    "                          datastore=def_data_store, \n",
    "                          output_path_on_compute=\"batchscoring/results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"name\": \"workspaceblobstore\",\n",
       "  \"container_name\": \"azureml-blobstore-2dd703c0-9f8b-4e31-bb4d-9ff3f50aa329\",\n",
       "  \"account_name\": \"amlworkbook2803154736\",\n",
       "  \"protocol\": \"https\",\n",
       "  \"endpoint\": \"core.windows.net\"\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_data_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = input_images.register(workspace = ws, name = \"input_images\")\n",
    "label_ds = label_ds.register(workspace = ws, name = \"label_ds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.isdir(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "\n",
    "if not os.path.exists(\"./models/inception_v3.ckpt\"):\n",
    "    response = urllib.request.urlretrieve(\"http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\", \"model.tar.gz\")\n",
    "    tar = tarfile.open(\"model.tar.gz\", \"r:gz\")\n",
    "    tar.extractall(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model inception\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    " \n",
    "model = Model.register(model_path=\"models/inception_v3.ckpt\",\n",
    "                       model_name=\"inception\",\n",
    "                       tags={\"pretrained\": \"inception\"},\n",
    "                       description=\"Imagenet trained tensorflow inception\",\n",
    "                       workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Attach the Remote Compute Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "compute_name = \"gpu-cluster-js01\"\n",
    "\n",
    "# checks to see if compute target already exists in workspace, else create it\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
    "except ComputeTargetException:\n",
    "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\",\n",
    "                                                   vm_priority=\"lowpriority\", \n",
    "                                                   min_nodes=0, \n",
    "                                                   max_nodes=1)\n",
    "\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a scoring script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting batch_scoring.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile batch_scoring.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tensorflow.contrib.slim.python.slim.nets import inception_v3\n",
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "image_size = 299\n",
    "num_channel = 3\n",
    "\n",
    "\n",
    "def get_class_label_dict(labels_dir):\n",
    "    label = []\n",
    "    labels_path = os.path.join(labels_dir, 'labels.txt')\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(labels_path).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label\n",
    "\n",
    "\n",
    "def init():\n",
    "    global g_tf_sess, probabilities, label_dict, input_images\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Start a tensorflow model serving\")\n",
    "    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n",
    "    parser.add_argument('--labels_dir', dest=\"labels_dir\", required=True)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    label_dict = get_class_label_dict(args.labels_dir)\n",
    "    classes_num = len(label_dict)\n",
    "\n",
    "    with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "        input_images = tf.placeholder(tf.float32, [1, image_size, image_size, num_channel])\n",
    "        logits, _ = inception_v3.inception_v3(input_images,\n",
    "                                              num_classes=classes_num,\n",
    "                                              is_training=False)\n",
    "        probabilities = tf.argmax(logits, 1)\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    g_tf_sess = tf.Session(config=config)\n",
    "    g_tf_sess.run(tf.global_variables_initializer())\n",
    "    g_tf_sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    model_path = Model.get_model_path(args.model_name)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(g_tf_sess, model_path)\n",
    "\n",
    "\n",
    "def file_to_tensor(file_path):\n",
    "    image_string = tf.read_file(file_path)\n",
    "    image = tf.image.decode_image(image_string, channels=3)\n",
    "\n",
    "    image.set_shape([None, None, None])\n",
    "    image = tf.image.resize_images(image, [image_size, image_size])\n",
    "    image = tf.divide(tf.subtract(image, [0]), [255])\n",
    "    image.set_shape([image_size, image_size, num_channel])\n",
    "    return image\n",
    "\n",
    "\n",
    "def run(mini_batch):\n",
    "    result_list = []\n",
    "    for file_path in mini_batch:\n",
    "        test_image = file_to_tensor(file_path)\n",
    "        out = g_tf_sess.run(test_image)\n",
    "        result = g_tf_sess.run(probabilities, feed_dict={input_images: [out]})\n",
    "        result_list.append(os.path.basename(file_path) + \": \" + label_dict[result[0]])\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_GPU_IMAGE\n",
    "\n",
    "cd = CondaDependencies.create(pip_packages=[\"tensorflow-gpu==1.15.2\",\n",
    "                                            \"azureml-core\", \"azureml-dataprep[fuse]\"])\n",
    "env = Environment(name=\"parallelenv\")\n",
    "env.python.conda_dependencies = cd\n",
    "env.docker.base_image = DEFAULT_GPU_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    environment=env,\n",
    "    entry_script=\"batch_scoring.py\",\n",
    "    source_directory=\".\",\n",
    "    output_action=\"append_row\",\n",
    "    mini_batch_size=\"20\",\n",
    "    error_threshold=1,\n",
    "    compute_target=compute_target,\n",
    "    process_count_per_node=2,\n",
    "    node_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Pipeline Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunStep\n",
    "from datetime import datetime\n",
    "\n",
    "parallel_step_name = \"batchscoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "label_config = label_ds.as_named_input(\"labels_input\")\n",
    "\n",
    "batch_score_step = ParallelRunStep(\n",
    "    name=parallel_step_name,\n",
    "    inputs=[input_images.as_named_input(\"input_images\")],\n",
    "    output=output_dir,\n",
    "    arguments=[\"--model_name\", \"inception\",\n",
    "               \"--labels_dir\", label_config],\n",
    "    side_inputs=[label_config],\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    allow_reuse=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batchscoring-202010211814 [dfc1df02][ee2484bc-8dd1-4175-92e2-6aedf9a55d3c], (This step will run and generate new outputs)\n",
      "Using data reference input_images_0 for StepId [1dfdec29][d9e70b7f-3a5b-4292-b7bc-7fb2b00e0139], (Consumers of this data are eligible to reuse prior runs.)Using data reference labels_input_0 for StepId [27256dad][ffd377a9-d8f7-4adc-a2c6-ac66eea45dc0], (Consumers of this data are eligible to reuse prior runs.)\n",
      "\n",
      "Submitted PipelineRun 54ecf2a5-b46f-4b50-bdd1-de706cddaf4c\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_scoring/runs/54ecf2a5-b46f-4b50-bdd1-de706cddaf4c?wsid=/subscriptions/b060ea58-a590-43cc-86ea-8ee676be2a76/resourcegroups/aml-workbook/workspaces/aml-workbook\n",
      "PipelineRunId: 54ecf2a5-b46f-4b50-bdd1-de706cddaf4c\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_scoring/runs/54ecf2a5-b46f-4b50-bdd1-de706cddaf4c?wsid=/subscriptions/b060ea58-a590-43cc-86ea-8ee676be2a76/resourcegroups/aml-workbook/workspaces/aml-workbook\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 69a76c2d-5f23-4896-bdc5-fc60604d0b5b\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_scoring/runs/69a76c2d-5f23-4896-bdc5-fc60604d0b5b?wsid=/subscriptions/b060ea58-a590-43cc-86ea-8ee676be2a76/resourcegroups/aml-workbook/workspaces/aml-workbook\n",
      "StepRun( batchscoring-202010211814 ) Status: NotStarted\n",
      "StepRun( batchscoring-202010211814 ) Status: Queued\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2020/10/21 16:16:38 Downloading source code...\n",
      "2020/10/21 16:16:40 Finished downloading source code\n",
      "2020/10/21 16:16:40 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2020/10/21 16:16:40 Successfully set up Docker network: acb_default_network\n",
      "2020/10/21 16:16:40 Setting up Docker configuration...\n",
      "2020/10/21 16:16:41 Successfully set up Docker configuration\n",
      "2020/10/21 16:16:41 Logging in to registry: 2dd703c09f8b4e31bb4d9ff3f50aa329.azurecr.io\n",
      "2020/10/21 16:16:42 Successfully logged into 2dd703c09f8b4e31bb4d9ff3f50aa329.azurecr.io\n",
      "2020/10/21 16:16:42 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/10/21 16:16:42 Scanning for dependencies...\n",
      "2020/10/21 16:16:43 Successfully scanned dependencies\n",
      "2020/10/21 16:16:43 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  60.93kB\n",
      "\n",
      "Step 1/15 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04:20200821.v1@sha256:652cba03ef8fd4937111da0bc9f204a4310105e87b08eea322c1b55850169a49\n",
      "sha256:652cba03ef8fd4937111da0bc9f204a4310105e87b08eea322c1b55850169a49: Pulling from azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04\n",
      "f7277927d38a: Pulling fs layer\n",
      "8d3eac894db4: Pulling fs layer\n",
      "edf72af6d627: Pulling fs layer\n",
      "3e4f86211d23: Pulling fs layer\n",
      "d6e9603ff777: Pulling fs layer\n",
      "5cad422780e2: Pulling fs layer\n",
      "8130687c8acb: Pulling fs layer\n",
      "c11e9246d621: Pulling fs layer\n",
      "0dfae24cbbd9: Pulling fs layer\n",
      "0bb049a6d391: Pulling fs layer\n",
      "1aef3da5021b: Pulling fs layer\n",
      "e5f03d63d02d: Pulling fs layer\n",
      "22533bcd68c8: Pulling fs layer\n",
      "a8c7deb5dc88: Pulling fs layer\n",
      "ef34b1adad4d: Pulling fs layer\n",
      "87e1451a8ae7: Pulling fs layer\n",
      "6a5d94939972: Pulling fs layer\n",
      "f4b1ab4ce7b5: Pulling fs layer\n",
      "0bb049a6d391: Waiting\n",
      "1aef3da5021b: Waiting\n",
      "e5f03d63d02d: Waiting\n",
      "22533bcd68c8: Waiting\n",
      "a8c7deb5dc88: Waiting\n",
      "ef34b1adad4d: Waiting\n",
      "87e1451a8ae7: Waiting\n",
      "6a5d94939972: Waiting\n",
      "f4b1ab4ce7b5: Waiting\n",
      "3e4f86211d23: Waiting\n",
      "d6e9603ff777: Waiting\n",
      "5cad422780e2: Waiting\n",
      "8130687c8acb: Waiting\n",
      "c11e9246d621: Waiting\n",
      "0dfae24cbbd9: Waiting\n",
      "edf72af6d627: Verifying Checksum\n",
      "edf72af6d627: Download complete\n",
      "8d3eac894db4: Verifying Checksum\n",
      "8d3eac894db4: Download complete\n",
      "3e4f86211d23: Verifying Checksum\n",
      "3e4f86211d23: Download complete\n",
      "d6e9603ff777: Verifying Checksum\n",
      "d6e9603ff777: Download complete\n",
      "8130687c8acb: Verifying Checksum\n",
      "8130687c8acb: Download complete\n",
      "5cad422780e2: Verifying Checksum\n",
      "5cad422780e2: Download complete\n",
      "f7277927d38a: Verifying Checksum\n",
      "f7277927d38a: Download complete\n",
      "0dfae24cbbd9: Retrying in 5 seconds\n",
      "0dfae24cbbd9: Retrying in 4 seconds\n",
      "0dfae24cbbd9: Retrying in 3 seconds\n",
      "StepRun( batchscoring-202010211814 ) Status: Running\n",
      "0dfae24cbbd9: Retrying in 2 seconds\n",
      "0dfae24cbbd9: Retrying in 1 second\n",
      "0bb049a6d391: Verifying Checksum\n",
      "0bb049a6d391: Download complete\n",
      "c11e9246d621: Verifying Checksum\n",
      "c11e9246d621: Download complete\n",
      "1aef3da5021b: Verifying Checksum\n",
      "1aef3da5021b: Download complete\n",
      "e5f03d63d02d: Verifying Checksum\n",
      "e5f03d63d02d: Download complete\n",
      "22533bcd68c8: Verifying Checksum\n",
      "22533bcd68c8: Download complete\n",
      "a8c7deb5dc88: Verifying Checksum\n",
      "a8c7deb5dc88: Download complete\n",
      "ef34b1adad4d: Verifying Checksum\n",
      "ef34b1adad4d: Download complete\n",
      "87e1451a8ae7: Verifying Checksum\n",
      "87e1451a8ae7: Download complete\n",
      "6a5d94939972: Verifying Checksum\n",
      "6a5d94939972: Download complete\n",
      "f4b1ab4ce7b5: Verifying Checksum\n",
      "f4b1ab4ce7b5: Download complete\n",
      "f7277927d38a: Pull complete\n",
      "8d3eac894db4: Pull complete\n",
      "edf72af6d627: Pull complete\n",
      "0dfae24cbbd9: Verifying Checksum\n",
      "0dfae24cbbd9: Download complete\n",
      "3e4f86211d23: Pull complete\n",
      "d6e9603ff777: Pull complete\n",
      "5cad422780e2: Pull complete\n",
      "8130687c8acb: Pull complete\n",
      "c11e9246d621: Pull complete\n",
      "0dfae24cbbd9: Pull complete\n",
      "0bb049a6d391: Pull complete\n",
      "1aef3da5021b: Pull complete\n",
      "e5f03d63d02d: Pull complete\n",
      "22533bcd68c8: Pull complete\n",
      "a8c7deb5dc88: Pull complete\n",
      "ef34b1adad4d: Pull complete\n",
      "87e1451a8ae7: Pull complete\n",
      "6a5d94939972: Pull complete\n",
      "f4b1ab4ce7b5: Pull complete\n",
      "Digest: sha256:652cba03ef8fd4937111da0bc9f204a4310105e87b08eea322c1b55850169a49\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04:20200821.v1@sha256:652cba03ef8fd4937111da0bc9f204a4310105e87b08eea322c1b55850169a49\n",
      " ---> 29d6cebaed25\n",
      "Step 2/15 : USER root\n",
      " ---> Running in fe7b7f1cf8eb\n",
      "Removing intermediate container fe7b7f1cf8eb\n",
      " ---> a38065834162\n",
      "Step 3/15 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 121634a0d004\n",
      "Removing intermediate container 121634a0d004\n",
      " ---> f0a6e108e01b\n",
      "Step 4/15 : WORKDIR /\n",
      " ---> Running in a063debb05db\n",
      "Removing intermediate container a063debb05db\n",
      " ---> c318b5c61fc3\n",
      "Step 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 3b5306d8ba76\n",
      "Step 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 4c4bdbc3ad46\n",
      "Removing intermediate container 4c4bdbc3ad46\n",
      " ---> 9557bf32e6e5\n",
      "Step 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 02f649cc85f1\n",
      "Step 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_b0827357ec606a0be8df05ade41cd431 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in bacfd4703541\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \n",
      "libedit-3.1          | 171 KB    | ####6      |  47% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "\n",
      "certifi-2020.6.20    | 160 KB    |            |   0% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "\n",
      "tk-8.6.10            | 3.2 MB    |            |   0% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "\n",
      "libffi-3.2.1         | 52 KB     |            |   0% \n",
      "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "\n",
      "setuptools-50.3.0    | 891 KB    |            |   0% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "\n",
      "pip-20.2.4           | 2.0 MB    |            |   0% \n",
      "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
      "\n",
      "wheel-0.35.1         | 36 KB     |            |   0% \n",
      "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ######4    |  64% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 128 KB    |            |   0% \n",
      "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \n",
      "python-3.6.2         | 27.0 MB   | #5         |  16% \n",
      "python-3.6.2         | 27.0 MB   | ####2      |  43% \n",
      "python-3.6.2         | 27.0 MB   | ######7    |  68% \n",
      "python-3.6.2         | 27.0 MB   | #########4 |  94% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_b0827357ec606a0be8df05ade41cd431/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.ldrqo5wb.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting tensorflow-gpu==1.15.2\n",
      "  Downloading tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0 MB)\n",
      "Collecting azureml-core~=1.15.0\n",
      "  Downloading azureml_core-1.15.0-py3-none-any.whl (2.0 MB)\n",
      "Collecting azureml-dataprep[fuse]\n",
      "  Downloading azureml_dataprep-2.4.0-py3-none-any.whl (28.2 MB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting six>=1.10.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /azureml-envs/azureml_b0827357ec606a0be8df05ade41cd431/lib/python3.6/site-packages (from tensorflow-gpu==1.15.2->-r /azureml-environment-setup/condaenv.ldrqo5wb.requirements.txt (line 1)) (0.35.1)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "Collecting protobuf>=3.6.1\n",
      "  Downloading protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n",
      "Collecting numpy<2.0,>=1.16.0\n",
      "  Downloading numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting ruamel.yaml>=0.15.35\n",
      "  Downloading ruamel.yaml-0.16.12-py2.py3-none-any.whl (111 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting azure-mgmt-resource<=10.2.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-10.2.0-py2.py3-none-any.whl (968 kB)\n",
      "Collecting azure-mgmt-storage<=11.2.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting azure-mgmt-authorization>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting azure-mgmt-keyvault<=2.2.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "Collecting azure-graphrbac>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting pyopenssl\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n",
      "  Downloading cryptography-3.1.1-cp35-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.19-py2.py3-none-any.whl (84 kB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.3.1-py2.py3-none-any.whl (145 kB)\n",
      "Collecting adal>=1.2.0\n",
      "  Downloading adal-1.2.4-py2.py3-none-any.whl (55 kB)\n",
      "Collecting requests>=2.19.1\n",
      "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.17-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting azure-identity<2.0.0,>=1.2.0\n",
      "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
      "Collecting azureml-dataprep-rslex<1.3.0a,>=1.2.0dev0\n",
      "  Downloading azureml_dataprep_rslex-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (7.9 MB)\n",
      "Collecting azureml-dataprep-native<25.0.0,>=24.0.0\n",
      "  Downloading azureml_dataprep_native-24.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting h5py\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /azureml-envs/azureml_b0827357ec606a0be8df05ade41cd431/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.2->-r /azureml-environment-setup/condaenv.ldrqo5wb.requirements.txt (line 1)) (50.3.0.post20201006)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.2-py3-none-any.whl (95 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
      "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.3-cp36-cp36m-manylinux1_x86_64.whl (400 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_b0827357ec606a0be8df05ade41cd431/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core~=1.15.0->-r /azureml-environment-setup/condaenv.ldrqo5wb.requirements.txt (line 2)) (2020.6.20)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.8.2-py2.py3-none-any.whl (122 kB)\n",
      "Collecting msal-extensions~=0.2.2\n",
      "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting msal<2.0.0,>=1.3.0\n",
      "  Downloading msal-1.5.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.3.1-py3-none-any.whl (5.3 kB)\n",
      "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: gast, wrapt, termcolor, fusepy\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7540 sha256=3d948711f79f3ce15894693dc27744bc5b473cabdba8a0a97d8f7973e328b295\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=66299 sha256=055678028efb52e93876496955dcf39c3ff07dd9bd3158c49012df08d027445a\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=511a39c5a23296d0bc19c95668a0ca9821c35b5444d97bfff70dd11c51630d68\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=ebadd7c1b01c0690d0f6883a5f96f0b5bf76eb59f5cc1a6b127e45189db3a8c0\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "Successfully built gast wrapt termcolor fusepy\n",
      "Installing collected packages: numpy, six, h5py, keras-applications, gast, google-pasta, wrapt, tensorflow-estimator, opt-einsum, astor, termcolor, keras-preprocessing, grpcio, protobuf, zipp, importlib-metadata, markdown, werkzeug, absl-py, tensorboard, tensorflow-gpu, python-dateutil, pycparser, cffi, cryptography, chardet, urllib3, idna, requests, PyJWT, adal, isodate, oauthlib, requests-oauthlib, msrest, msrestazure, contextlib2, ruamel.yaml.clib, ruamel.yaml, pyasn1, pyopenssl, ndg-httpsclient, azure-common, azure-mgmt-resource, azure-mgmt-storage, azure-mgmt-containerregistry, pytz, azure-mgmt-authorization, azure-mgmt-keyvault, azure-graphrbac, pathspec, jmespath, backports.weakref, backports.tempfile, jeepney, SecretStorage, websocket-client, docker, jsonpickle, azureml-core, distro, dotnetcore2, cloudpickle, azure-core, msal, portalocker, msal-extensions, azure-identity, azureml-dataprep-rslex, azureml-dataprep-native, fusepy, azureml-dataprep\n",
      "Successfully installed PyJWT-1.7.1 SecretStorage-3.1.2 absl-py-0.10.0 adal-1.2.4 astor-0.8.1 azure-common-1.1.25 azure-core-1.8.2 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-10.2.0 azure-mgmt-storage-11.2.0 azureml-core-1.15.0 azureml-dataprep-2.4.0 azureml-dataprep-native-24.0.0 azureml-dataprep-rslex-1.2.0 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.3 chardet-3.0.4 cloudpickle-1.6.0 contextlib2-0.6.0.post1 cryptography-3.1.1 distro-1.5.0 docker-4.3.1 dotnetcore2-2.1.17 fusepy-3.0.1 gast-0.2.2 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 idna-2.10 importlib-metadata-2.0.0 isodate-0.6.0 jeepney-0.4.3 jmespath-0.10.0 jsonpickle-1.4.1 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.2 msal-1.5.0 msal-extensions-0.2.2 msrest-0.6.19 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.19.2 oauthlib-3.1.0 opt-einsum-3.3.0 pathspec-0.8.0 portalocker-1.7.1 protobuf-3.13.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2020.1 requests-2.24.0 requests-oauthlib-1.3.0 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2 six-1.15.0 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2 termcolor-1.1.0 urllib3-1.25.11 websocket-client-0.57.0 werkzeug-1.0.1 wrapt-1.12.1 zipp-3.3.1\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_b0827357ec606a0be8df05ade41cd431\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "WARNING: /root/.conda/pkgs does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing intermediate container bacfd4703541\n",
      " ---> 7459fa485963\n",
      "Step 9/15 : ENV PATH /azureml-envs/azureml_b0827357ec606a0be8df05ade41cd431/bin:$PATH\n",
      " ---> Running in 3065f9588586\n",
      "Removing intermediate container 3065f9588586\n",
      " ---> 6db3bb68d752\n",
      "Step 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_b0827357ec606a0be8df05ade41cd431\n",
      " ---> Running in 49b53c9cdb7a\n",
      "Removing intermediate container 49b53c9cdb7a\n",
      " ---> 5d052b5075e0\n",
      "Step 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_b0827357ec606a0be8df05ade41cd431/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 4ca882a8ffa2\n",
      "Removing intermediate container 4ca882a8ffa2\n",
      " ---> d582a66534f5\n",
      "Step 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 86fb107b618f\n",
      "Step 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in a1e80edc6d1b\n",
      "Removing intermediate container a1e80edc6d1b\n",
      " ---> 7b7afb9d14e4\n",
      "Step 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 3d6da63bd576\n",
      "Removing intermediate container 3d6da63bd576\n",
      " ---> f97cd012c754\n",
      "Step 15/15 : CMD [\"bash\"]\n",
      " ---> Running in e182a8294a90\n",
      "Removing intermediate container e182a8294a90\n",
      " ---> 6a5da88cf50a\n",
      "Successfully built 6a5da88cf50a\n",
      "Successfully tagged 2dd703c09f8b4e31bb4d9ff3f50aa329.azurecr.io/azureml/azureml_5713f1f2bc019e8bf399724357245fc2:latest\n",
      "2020/10/21 16:20:47 Successfully executed container: acb_step_0\n",
      "2020/10/21 16:20:47 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/10/21 16:20:47 Pushing image: 2dd703c09f8b4e31bb4d9ff3f50aa329.azurecr.io/azureml/azureml_5713f1f2bc019e8bf399724357245fc2:latest, attempt 1\n",
      "The push refers to repository [2dd703c09f8b4e31bb4d9ff3f50aa329.azurecr.io/azureml/azureml_5713f1f2bc019e8bf399724357245fc2]\n",
      "2679ea9afa80: Preparing\n",
      "3f807385221c: Preparing\n",
      "32ebbe01768a: Preparing\n",
      "0d7ae5d28afe: Preparing\n",
      "270a7435b7c9: Preparing\n",
      "f747d7252a1a: Preparing\n",
      "80e085142144: Preparing\n",
      "3d69c415d1f0: Preparing\n",
      "cf59bc701d30: Preparing\n",
      "3cf57cc1b3bc: Preparing\n",
      "019f14bc11c8: Preparing\n",
      "1f16665d954b: Preparing\n",
      "a0c9064424e4: Preparing\n",
      "12d67fac46a2: Preparing\n",
      "c36fc92de581: Preparing\n",
      "524881d0563d: Preparing\n",
      "d05c249e6b9f: Preparing\n",
      "fc8a172f94e8: Preparing\n",
      "48001c8a7ddb: Preparing\n",
      "6dce9683cb41: Preparing\n",
      "e79142719515: Preparing\n",
      "aeda103e78c9: Preparing\n",
      "2558e637fbff: Preparing\n",
      "f749b9b0fb21: Preparing\n",
      "f747d7252a1a: Waiting\n",
      "80e085142144: Waiting\n",
      "3d69c415d1f0: Waiting\n",
      "cf59bc701d30: Waiting\n",
      "3cf57cc1b3bc: Waiting\n",
      "019f14bc11c8: Waiting\n",
      "1f16665d954b: Waiting\n",
      "a0c9064424e4: Waiting\n",
      "12d67fac46a2: Waiting\n",
      "c36fc92de581: Waiting\n",
      "524881d0563d: Waiting\n",
      "d05c249e6b9f: Waiting\n",
      "fc8a172f94e8: Waiting\n",
      "aeda103e78c9: Waiting\n",
      "2558e637fbff: Waiting\n",
      "f749b9b0fb21: Waiting\n",
      "48001c8a7ddb: Waiting\n",
      "6dce9683cb41: Waiting\n",
      "e79142719515: Waiting\n",
      "0d7ae5d28afe: Pushed\n",
      "270a7435b7c9: Pushed\n",
      "2679ea9afa80: Pushed\n",
      "32ebbe01768a: Pushed\n",
      "f747d7252a1a: Pushed\n",
      "80e085142144: Pushed\n",
      "3d69c415d1f0: Pushed\n",
      "cf59bc701d30: Pushed\n",
      "a0c9064424e4: Pushed\n",
      "3cf57cc1b3bc: Pushed\n",
      "019f14bc11c8: Pushed\n",
      "1f16665d954b: Pushed\n",
      "12d67fac46a2: Pushed\n",
      "fc8a172f94e8: Pushed\n",
      "48001c8a7ddb: Pushed\n",
      "6dce9683cb41: Pushed\n",
      "e79142719515: Pushed\n",
      "aeda103e78c9: Pushed\n",
      "2558e637fbff: Pushed\n",
      "c36fc92de581: Pushed\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[batch_score_step])\n",
    "pipeline_run = Experiment(ws, 'batch_scoring').submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and review output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch_run = next(pipeline_run.get_children())\n",
    "batch_output = batch_run.get_output_data(\"scores\")\n",
    "batch_output.download(local_path=\"inception_results\")\n",
    "\n",
    "for root, dirs, files in os.walk(\"inception_results\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\"parallel_run_step.txt\"):\n",
    "            result_file = os.path.join(root, file)\n",
    "\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"Filename\", \"Prediction\"]\n",
    "print(\"Prediction has \", df.shape[0], \" rows\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
